{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc65e7d-b676-46fa-af71-298a78d7c82d",
   "metadata": {},
   "source": [
    "## 测试环境代理是否正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46af366-a6fa-4bfe-8abd-7a1e85bc4047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HuggingFace 连接成功，状态码: 200\n",
      "Test server is ubuntu22.04 GPU 2080Ti 22G\n"
     ]
    }
   ],
   "source": [
    "# 测试代理\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# 设置代理环境变量\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['ALL_PROXY'] = 'socks5://127.0.0.1:7891'\n",
    "#os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# 测试代理连接\n",
    "try:\n",
    "    response = requests.get('https://huggingface.co', timeout=10)\n",
    "    print(\"✅ HuggingFace 连接成功，状态码:\", response.status_code)\n",
    "    print(\"Test server is ubuntu22.04 GPU 2080Ti 22G\")\n",
    "except Exception as e:\n",
    "    print(\"连接失败:\", e)\n",
    "\n",
    "# 设置 HuggingFace 缓存路径\n",
    "os.environ['HF_HOME'] = '/home/KevinLiangX/Codes/LLM-quickstart-main/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/home/KevinLiangX/Codes/LLM-quickstart-main/hf_hu'\n",
    "\n",
    "\n",
    "# 服务器环境 ubuntu22.04 GPU 2080Ti 22G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2de8ba-d02a-490e-8c2f-7211f333bb69",
   "metadata": {},
   "source": [
    "## 设置全局参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8279227-8967-416d-abd5-84abf05348e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"openai/whisper-large-v2\"\n",
    "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
    "\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "task = \"transcribe\"\n",
    "dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
    "\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a712794f-f33f-469e-9d03-3d1a58ab878b",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69628c4f-e23f-4618-947a-5b853c22462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 加载数据集...\n",
      "✅ 全部加载完成: 训练29056 验证10581\n"
     ]
    }
   ],
   "source": [
    "# ## 优化的数据集加载方案\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# 设置缓存目录，避免重复下载\n",
    "cache_dir = \"/home/KevinLiangX/Codes/LLM-quickstart-main/hf_cache\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "def load_dataset_with_cache(dataset_name, language_abbr, split, cache_dir):\n",
    "    \"\"\"带缓存的数据集加载，避免重复下载\"\"\"\n",
    "    try:\n",
    "        return load_dataset(\n",
    "            dataset_name, \n",
    "            language_abbr, \n",
    "            split=split, \n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"加载{split}失败: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"📥 加载数据集...\")\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "# 分别加载，失败时可以单独重试\n",
    "common_voice[\"train\"] = load_dataset_with_cache(dataset_name, language_abbr, \"train\", cache_dir)\n",
    "common_voice[\"validation\"] = load_dataset_with_cache(dataset_name, language_abbr, \"validation\", cache_dir)\n",
    "\n",
    "# 检查加载结果\n",
    "if all(v is not None for v in common_voice.values()):\n",
    "    print(f\"✅ 全部加载完成: 训练{len(common_voice['train'])} 验证{len(common_voice['validation'])}\")\n",
    "else:\n",
    "    print(\"❌ 部分数据集加载失败，请检查网络连接\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451211bf-4d68-482e-ae13-4422fb006ff7",
   "metadata": {},
   "source": [
    "## 预处理训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7408a1a-3bcf-4b82-aa6a-3ba4c3867f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f6917c-a63d-42a1-b0c4-dff9c667ca34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoTokenizer, AutoProcessor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "\n",
    "## 移除数据集中不必要的字段\n",
    "common_voice = common_voice.remove_columns(\n",
    "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
    ")\n",
    "\n",
    "## 降低音频数据的采样16kHz\n",
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a0575-f995-43a2-8678-b0c852bf74da",
   "metadata": {},
   "source": [
    "## 使用全量数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e5208c6-437d-4648-a191-61b1534c0144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa9bddeea74dcc93dc6b89fc001493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/10581 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "To support decoding audio data, please install 'torchcodec'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py\", line 586, in _write_generator_to_queue\n    # The import has a comment with 'From:', we'll retrieve it from the given url\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3650, in _map_single\n    def flatten_indices(\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3624, in iter_outputs\n    function=partial(\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py\", line 3547, in apply_function\n    desc: Optional[str] = None,\n  File \"/tmp/ipykernel_2191832/2988829012.py\", line 7, in prepare_dataset\n    audio = batch[\"audio\"]\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 284, in __getitem__\n    self.keys_to_format.remove(key)\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 379, in format\n    \"\"\"\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 464, in format_column\n    def format_batch(self, pa_table: pa.Table) -> pd.DataFrame:\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/formatting/formatting.py\", line 227, in decode_column\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/features/features.py\", line 2116, in decode_column\n    del flattened[column_name]\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/features/features.py\", line 2117, in <listcomp>\n    self = flattened\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/features/features.py\", line 1405, in decode_nested_example\n    n_offsets = reduce(mul, arr.shape[: arr.ndim - i - 1], 1)\n  File \"/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/features/audio.py\", line 172, in decode_example\n    source_url = path.split(\"::\")[-1]\nImportError: To support decoding audio data, please install 'torchcodec'.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenized_common_voice \u001b[38;5;241m=\u001b[39m \u001b[43mcommon_voice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/dataset_dict.py:946\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, with_split, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc, try_original_type)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[1;32m    944\u001b[0m     function \u001b[38;5;241m=\u001b[39m bind(function, split)\n\u001b[0;32m--> 946\u001b[0m dataset_dict[split] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_original_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_original_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[1;32m    968\u001b[0m     function \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunc\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3309\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[0m\n\u001b[1;32m   3306\u001b[0m os\u001b[38;5;241m.\u001b[39menviron \u001b[38;5;241m=\u001b[39m prev_env\n\u001b[1;32m   3307\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[1;32m   3310\u001b[0m     pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39munprocessed_kwargs_per_job\n\u001b[1;32m   3311\u001b[0m ):\n\u001b[1;32m   3312\u001b[0m     check_if_shard_done(rank, done, content)\n\u001b[1;32m   3314\u001b[0m pool\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:626\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/datasets/utils/py_utils.py:626\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[0;32m/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/multiprocess/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mImportError\u001b[0m: To support decoding audio data, please install 'torchcodec'."
     ]
    }
   ],
   "source": [
    "tokenized_common_voice = common_voice.map(prepare_dataset, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c86fa8-75a7-4933-9392-44fc91dd51de",
   "metadata": {},
   "source": [
    "## 自定义语音数据整理器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d51c64-e101-48f9-8fed-6ad6702a2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "# 定义一个针对语音到文本任务的数据整理器类\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any  # 处理器结合了特征提取器和分词器\n",
    "\n",
    "    # 整理器函数，将特征列表处理成一个批次\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 从特征列表中提取输入特征，并填充以使它们具有相同的形状\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 从特征列表中提取标签特征（文本令牌），并进行填充\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # 使用-100替换标签中的填充区域，-100通常用于在损失计算中忽略填充令牌\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # 如果批次中的所有序列都以句子开始令牌开头，则移除它\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        # 将处理过的标签添加到批次中\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch  # 返回最终的批次，准备好进行训练或评估\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b905df-af9c-4096-b03f-ba02b78cdd38",
   "metadata": {},
   "source": [
    "## 模型准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c9416bb-1894-48bc-bbbc-659045338ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/peft/utils/other.py:141: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## 加载预训练模型(int8精度)\n",
    "from transformers import AutoModelForSpeechSeq2Seq\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, load_in_8bit=True, device_map=\"auto\")\n",
    "\n",
    "model.config.forced_decoder_ids = None \n",
    "\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "# 转换特定参数int8为32\n",
    "from peft import prepare_model_for_int8_training\n",
    "\n",
    "model = prepare_model_for_int8_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3def172-daa5-4d8c-b0d6-4c7d272ccbae",
   "metadata": {},
   "source": [
    "##  LoRA Adapter配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d72c466-247b-43b4-913d-645ff3d0be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,966,080 || all params: 1,545,271,040 || trainable%: 0.12723204856023188\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
    "\n",
    "# 创建一个LoraConfig对象，用于设置LoRA（Low-Rank Adaptation）的配置参数\n",
    "config = LoraConfig(\n",
    "    r=4,  # LoRA的秩，影响LoRA矩阵的大小\n",
    "    lora_alpha=64,  # LoRA适应的比例因子\n",
    "    # 指定将LoRA应用到的模型模块，通常是attention和全连接层的投影。\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,  # 在LoRA模块中使用的dropout率\n",
    "    bias=\"none\",  # 设置bias的使用方式，这里没有使用bias\n",
    ")\n",
    "\n",
    "# 获取PEFT模型\n",
    "peft_model = get_peft_model(model, config)\n",
    "# 打印 LoRA 微调训练的模型参数，查看参与微调的参数量\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e58be9-6919-4c22-8936-1370b67bf033",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd484b77-9d2a-404e-8160-452443a96bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置超参\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "# 设置序列到序列模型训练的参数\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_dir,  \n",
    "    per_device_train_batch_size=48, \n",
    "    learning_rate=1e-3,  \n",
    "    num_train_epochs=3,  \n",
    "    \n",
    "    \n",
    "    evaluation_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    warmup_steps=200,  # 在训练初期增加学习率的步数，有助于稳定训练\n",
    "    fp16=True,  # 启用混合精度训练，可以提高训练速度，同时减少内存使用\n",
    "    gradient_accumulation_steps=1,   # 梯度累积，模拟更大batch\n",
    "    per_device_eval_batch_size=64,  # 每个设备上的评估批量大小\n",
    "    dataloader_num_workers=8,       # 多进程数据加载\n",
    "    generation_max_length=256,  # 生成任务的最大长度\n",
    "    logging_steps=20,  # 指定日志记录的步骤，用于跟踪训练进度\n",
    "    remove_unused_columns=False,  # 是否删除不使用的列，以减少数据处理开销\n",
    "    label_names=[\"labels\"],  # 指定标签列的名称，用于训练过程中\n",
    "\n",
    "    save_total_limit=3,                   # 只保存最新checkpoint\n",
    "    load_best_model_at_end=True,          # 加载最佳模型\n",
    "    metric_for_best_model=\"eval_loss\",    # 基于validation loss选择\n",
    "\n",
    ")\n",
    "\n",
    "# 实例化 Seq2SeqTraniner 训练器\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=peft_model,\n",
    "    train_dataset=tokenized_common_voice[\"train\"],\n",
    "    eval_dataset=tokenized_common_voice[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "peft_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a2a6e-fadc-418e-b66d-e59e51a41e61",
   "metadata": {},
   "source": [
    "## 启动训练 并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3af2baa3-6d3b-4fb5-a6b5-9ea97d32d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1818' max='1818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1818/1818 6:10:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.417392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.389227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.388295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1818, training_loss=0.31751476210204943, metrics={'train_runtime': 22241.1447, 'train_samples_per_second': 3.919, 'train_steps_per_second': 0.082, 'total_flos': 1.85319357677568e+20, 'train_loss': 0.31751476210204943, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 启动训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07af45a9-8738-43c6-9aa2-da0c7ff2638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存LoRA模型\n",
    "trainer.save_model(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b936217-0d12-4ac0-b405-a421e96fbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看Lora模型信息\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f69b9f-f3e2-40ee-b0ac-78cb5af6ad39",
   "metadata": {},
   "source": [
    "## 加载模型进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44af47d6-e55f-4143-8dd9-0f3c8f7436e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修复模型加载问题...\n",
      "PEFT配置: openai/whisper-large-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38fa113d07940b4ba76935baba49270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":\"2025-07-26T04:58:18.936583Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Reqwest(reqwest::Error { kind: Request, source: hyper_util::client::legacy::Error(Connect, Os { code: 32, kind: BrokenPipe, message: \\\"Broken pipe\\\" }) }). Retrying...\"},\"filename\":\"/home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs\",\"line_number\":242}\n",
      "{\"timestamp\":\"2025-07-26T04:58:18.936641Z\",\"level\":\"WARN\",\"fields\":{\"message\":\"Retry attempt #0. Sleeping 2.038532554s before the next attempt\"},\"filename\":\"/root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs\",\"line_number\":171}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6a15ff61cb4730b84592413cda5d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用safetensors格式加载成功\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
    "\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "language_decode = \"chinese\"\n",
    "task = \"transcribe\"\n",
    "\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n",
    "from peft import PeftConfig, PeftModel\n",
    "import torch\n",
    "\n",
    "print(\"修复模型加载问题...\")\n",
    "\n",
    "# 1. 从本地加载PEFT配置\n",
    "peft_config = PeftConfig.from_pretrained(model_dir)\n",
    "print(f\"PEFT配置: {peft_config.base_model_name_or_path}\")\n",
    "\n",
    "# 2. 修复base model加载 - 处理pytorch_model.bin缺失\n",
    "try:\n",
    "    base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        peft_config.base_model_name_or_path, \n",
    "        load_in_8bit=True, \n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,  # 指定数据类型\n",
    "        use_safetensors=True,       # 优先使用safetensors格式\n",
    "    )\n",
    "    print(\"使用safetensors格式加载成功\")\n",
    "except Exception as e:\n",
    "    print(f\"safetensors加载失败: {e}\")\n",
    "    print(\"尝试重新下载模型...\")\n",
    "    \n",
    "    # 重新下载完整模型\n",
    "    base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        peft_config.base_model_name_or_path, \n",
    "        load_in_8bit=True, \n",
    "        device_map=\"auto\",\n",
    "        force_download=True,        # 强制重新下载\n",
    "        resume_download=True        # 支持断点续传\n",
    "    )\n",
    "    print(\"重新下载完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a04301-930d-424e-9a4e-ce72bdcb56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA适配器加载成功\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5e35ee541b42209ac47b79b3d81a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec6084d5c0844c0b20284c3afc1e54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3014aa6d21a4a6192412e4baa1a5028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d5489e893645e19f511e974e7fc285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8896b21acf644688ab9248cf7d24182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c89c13ecfd444286193ba7ff310428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eb0d77433048e0946f2e20fe036ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dfa9f19c7e4887a6247d89f0255acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有组件加载完成\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51865, 1280, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (q_proj): lora.Linear8bitLt(\n",
       "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1280, out_features=4, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=4, out_features=1280, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1280, out_features=51865, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 继续加载LoRA适配器和其他组件\n",
    "\n",
    "# 3. 加载本地LoRA适配器\n",
    "peft_model = PeftModel.from_pretrained(base_model, model_dir)\n",
    "print(\"LoRA适配器加载成功\")\n",
    "\n",
    "# 4. 加载tokenizer和processor\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, \n",
    "    language=language, \n",
    "    task=task\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, \n",
    "    language=language, \n",
    "    task=task\n",
    ")\n",
    "feature_extractor = processor.feature_extractor\n",
    "\n",
    "print(\"所有组件加载完成\")\n",
    "\n",
    "# 设置模型为评估模式\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91bc649d-4c37-4199-a541-5c6cf6179eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建ASR pipeline（修复device冲突）...\n",
      "Pipeline创建成功\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutomaticSpeechRecognitionPipeline\n",
    "\n",
    "print(\"创建ASR pipeline（修复device冲突）...\")\n",
    "\n",
    "# 不指定device参数，让accelerate自动管理\n",
    "pipeline = AutomaticSpeechRecognitionPipeline(\n",
    "    model=peft_model, \n",
    "    tokenizer=tokenizer, \n",
    "    feature_extractor=feature_extractor\n",
    "    # 移除 device=0 参数\n",
    ")\n",
    "\n",
    "# 获取强制解码ID\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=language_decode, task=task)\n",
    "\n",
    "print(\"Pipeline创建成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5b96d2-37e2-41a8-b696-3186d5b5e6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 测试微调模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微调模型转录结果:\n",
      "   这是一段测试用于WhisperLarge V2模型的自动语音识别测试。\n"
     ]
    }
   ],
   "source": [
    "test_audio = \"data/audio/test_zh.flac\"\n",
    "\n",
    "print(\"测试微调模型...\")\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    result = pipeline(\n",
    "        test_audio, \n",
    "        max_new_tokens=255,\n",
    "        generate_kwargs={\n",
    "            \"language\": \"chinese\", \n",
    "            \"task\": \"transcribe\"   \n",
    "        }\n",
    "    )\n",
    "    text = result[\"text\"]\n",
    "\n",
    "print(f\"微调模型转录结果:\")\n",
    "print(f\"   {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4ffa8-7a7f-4df6-a73f-380aedc7e960",
   "metadata": {},
   "source": [
    "## OpenAI Whisper LoRA 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcf6ea3-ca96-4541-89b2-66129b8ed0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微调模型加载完成\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"openai/whisper-large-v2\"\n",
    "model_dir = \"models/whisper-large-v2-asr-int8\"\n",
    "\n",
    "language = \"Chinese (China)\"\n",
    "language_abbr = \"zh-CN\"\n",
    "task = \"transcribe\"\n",
    "dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoTokenizer, AutoProcessor\n",
    "from peft import PeftConfig, PeftModel\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(model_dir)\n",
    "\n",
    "base_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    peft_config.base_model_name_or_path, load_in_8bit=True, device_map=\"auto\"\n",
    ")\n",
    "base_model.requires_grad_(False)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, model_dir)\n",
    "peft_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "processor = AutoProcessor.from_pretrained(peft_config.base_model_name_or_path, language=language, task=task)\n",
    "feature_extractor = processor.feature_extractor\n",
    "print(\"微调模型加载完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f796ff6-0336-435c-a7a1-a161b75a33b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载测试数据集（使用缓存）...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mozilla-foundation/common_voice_11_0 couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'zh-CN' at /home/KevinLiangX/Codes/LLM-quickstart-main/hf_cache/mozilla-foundation___common_voice_11_0/zh-CN/11.0.0/3f27acf10f303eac5b6fbbbe02495aeddb46ecffdb0a2fe3507fcfbf89094631 (last modified on Sat Jul 26 15:05:05 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集加载成功（使用缓存）: 10581 样本\n"
     ]
    }
   ],
   "source": [
    "# 优化数据集加载 - 使用缓存，避免重新下载\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict, Audio\n",
    "\n",
    "# 设置缓存目录，使用之前训练时的缓存\n",
    "cache_dir = \"/home/KevinLiangX/Codes/LLM-quickstart-main/hf_cache\"  # 使用之前的缓存目录\n",
    "\n",
    "print(\"加载测试数据集（使用缓存）...\")\n",
    "\n",
    "def load_dataset_with_cache(dataset_name, language_abbr, split, cache_dir):\n",
    "    \"\"\"使用缓存加载数据集，避免重新下载\"\"\"\n",
    "    try:\n",
    "        return load_dataset(\n",
    "            dataset_name, \n",
    "            language_abbr, \n",
    "            split=split, \n",
    "            trust_remote_code=True,\n",
    "            cache_dir=cache_dir  # 使用已有缓存\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"加载{split}失败: {e}\")\n",
    "        return None\n",
    "\n",
    "# 只加载测试集，使用缓存\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"test\"] = load_dataset_with_cache(dataset_name, language_abbr, \"test\", cache_dir)\n",
    "\n",
    "if common_voice[\"test\"] is not None:\n",
    "    print(f\"测试集加载成功（使用缓存）: {len(common_voice['test'])} 样本\")\n",
    "else:\n",
    "    print(\"测试集加载失败\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76215b57-e038-4847-b01b-8fb732b278b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已预处理完毕\n"
     ]
    }
   ],
   "source": [
    "common_voice = common_voice.remove_columns(\n",
    "    [\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"]\n",
    ")\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "tokenized_common_voice = common_voice.map(prepare_dataset)\n",
    "print(\"数据已预处理完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970b0503-0985-4d59-862c-e02cb853ca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据整理器准备完成\n"
     ]
    }
   ],
   "source": [
    "# 数据整理器 \n",
    "\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "print(\"数据整理器准备完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74bdb255-034a-494c-9bf3-f7414198a105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解决WER模块问题...\n",
      "\n",
      "重新测试...\n",
      "新的evaluate版本: 0.4.1\n",
      " 测试失败: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /api/spaces?filter=metric (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f9139b5cdc0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n",
      "\n",
      " 版本修复完成\n"
     ]
    }
   ],
   "source": [
    "# 解决WER模块版本问题\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"解决WER模块问题...\")\n",
    "\n",
    "# 4. 重新导入并测试\n",
    "print(\"\\n重新测试...\")\n",
    "try:\n",
    "    # 重新导入evaluate\n",
    "    import importlib\n",
    "    import evaluate\n",
    "    importlib.reload(evaluate)\n",
    "    \n",
    "    print(f\"新的evaluate版本: {evaluate.__version__}\")\n",
    "    \n",
    "    # 检查WER是否现在可用\n",
    "    available_metrics = evaluate.list_evaluation_modules(module_type=\"metric\")\n",
    "    print(f\" 可用指标数量: {len(available_metrics)}\")\n",
    "    \n",
    "    if \"wer\" in available_metrics:\n",
    "        print(\" WER现在可用了！\")\n",
    "        \n",
    "        # 测试加载\n",
    "        metric = evaluate.load(\"wer\")\n",
    "        print(\"WER加载成功\")\n",
    "        \n",
    "        # 测试计算\n",
    "        wer_score = metric.compute(predictions=[\"hello\"], references=[\"hello\"])\n",
    "        print(f\" WER计算成功: {wer_score}\")\n",
    "        \n",
    "    else:\n",
    "        print(\" WER仍然不可用\")\n",
    "        print(\" 搜索包含'wer'的指标...\")\n",
    "        wer_like = [m for m in available_metrics if 'wer' in m.lower()]\n",
    "        print(f\"包含'wer'的指标: {wer_like}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" 测试失败: {e}\")\n",
    "\n",
    "print(\"\\n 版本修复完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "206be23f-3333-41f0-8d62-c77ef8f3cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 使用可用的WER模块...\n",
      " 加载 argmaxinc/detailed-wer...\n",
      " detailed-wer 加载失败: Couldn't find a module script at /home/KevinLiangX/Codes/LLM-quickstart-main/peft/argmaxinc/detailed-wer/detailed-wer.py. Module 'argmaxinc/detailed-wer' doesn't exist on the Hugging Face Hub either.\n",
      "\n",
      " WER模块测试完成\n"
     ]
    }
   ],
   "source": [
    "# 使用可用的detailed-wer模块\n",
    "\n",
    "import evaluate\n",
    "\n",
    "print(\" 使用可用的WER模块...\")\n",
    "\n",
    "try:\n",
    "    # 使用找到的detailed-wer模块\n",
    "    print(\" 加载 argmaxinc/detailed-wer...\")\n",
    "    metric = evaluate.load(\"argmaxinc/detailed-wer\")\n",
    "    print(\" detailed-wer 加载成功！\")\n",
    "    \n",
    "    # 测试功能\n",
    "    test_predictions = [\"这是一个测试\", \"你好世界\"]\n",
    "    test_references = [\"这是一个测试\", \"你好世界\"]\n",
    "    \n",
    "    result = metric.compute(predictions=test_predictions, references=test_references)\n",
    "    print(f\" WER计算成功: {result}\")\n",
    "    \n",
    "    # 检查返回的结果格式\n",
    "    print(f\" 结果类型: {type(result)}\")\n",
    "    print(f\" 结果内容: {result}\")\n",
    "    \n",
    "    # 如果是字典，查看包含的键\n",
    "    if isinstance(result, dict):\n",
    "        print(f\" 可用键: {list(result.keys())}\")\n",
    "        \n",
    "        # 通常WER在'wer'键中\n",
    "        if 'wer' in result:\n",
    "            wer_score = result['wer']\n",
    "            print(f\" WER分数: {wer_score}\")\n",
    "        elif 'word_error_rate' in result:\n",
    "            wer_score = result['word_error_rate']\n",
    "            print(f\" WER分数: {wer_score}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" detailed-wer 加载失败: {e}\")\n",
    "\n",
    "print(\"\\n WER模块测试完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3833b737-3ceb-44eb-9e95-2edc40bf4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 修复evaluate路径问题...\n",
      " 当前工作目录: /home/KevinLiangX/Codes/LLM-quickstart-main/peft\n",
      " 没有发现干扰的本地目录\n",
      " 切换到临时目录: /tmp/tmp_sk0wbe5\n",
      " 在干净环境中重新加载evaluate...\n",
      " 尝试从HuggingFace Hub加载WER...\n",
      " 尝试加载: wer\n",
      " 失败: Couldn't find a module script at /tmp/tmp_sk0wbe5/wer/wer.py. Module 'wer' doesn't exist on the Hugging Face Hub either.\n",
      " 尝试加载: evaluate-metric/wer\n",
      " 失败: Couldn't find a module script at /tmp/tmp_sk0wbe5/evaluate-metric/wer/wer.py. Module 'evaluate-metric/wer' doesn't exist on the Hugging Face Hub either.\n",
      " 尝试加载: huggingface/evaluate-metric-wer\n",
      " 失败: Couldn't find a module script at /tmp/tmp_sk0wbe5/huggingface/evaluate-metric-wer/evaluate-metric-wer.py. Module 'huggingface/evaluate-metric-wer' doesn't exist on the Hugging Face Hub either.\n",
      " 所有WER模块都加载失败\n",
      " 恢复到原目录: /home/KevinLiangX/Codes/LLM-quickstart-main/peft\n",
      " 路径修复测试完成\n"
     ]
    }
   ],
   "source": [
    "# 修复evaluate路径问题\n",
    "\n",
    "import os\n",
    "import evaluate\n",
    "\n",
    "print(\" 修复evaluate路径问题...\")\n",
    "\n",
    "# 1. 检查当前工作目录\n",
    "current_dir = os.getcwd()\n",
    "print(f\" 当前工作目录: {current_dir}\")\n",
    "\n",
    "# 2. 检查是否有本地的evaluate模块干扰\n",
    "local_evaluate_dirs = []\n",
    "for item in os.listdir('.'):\n",
    "    if 'evaluate' in item.lower() or 'wer' in item.lower():\n",
    "        local_evaluate_dirs.append(item)\n",
    "\n",
    "if local_evaluate_dirs:\n",
    "    print(f\" 发现可能干扰的本地目录: {local_evaluate_dirs}\")\n",
    "else:\n",
    "    print(\" 没有发现干扰的本地目录\")\n",
    "\n",
    "# 3. 临时切换到系统临时目录\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\" 切换到临时目录: {temp_dir}\")\n",
    "\n",
    "original_dir = os.getcwd()\n",
    "os.chdir(temp_dir)\n",
    "\n",
    "try:\n",
    "    # 4. 在干净环境中重新导入evaluate\n",
    "    import importlib\n",
    "    importlib.reload(evaluate)\n",
    "    \n",
    "    print(\" 在干净环境中重新加载evaluate...\")\n",
    "    \n",
    "    # 5. 强制从Hub下载\n",
    "    print(\" 尝试从HuggingFace Hub加载WER...\")\n",
    "    \n",
    "    # 设置环境变量确保在线模式\n",
    "    os.environ['HF_DATASETS_OFFLINE'] = '0'\n",
    "    os.environ['HF_EVALUATE_OFFLINE'] = '0'\n",
    "    \n",
    "    # 尝试不同的WER模块\n",
    "    wer_modules = [\n",
    "        \"wer\",\n",
    "        \"evaluate-metric/wer\", \n",
    "        \"huggingface/evaluate-metric-wer\"\n",
    "    ]\n",
    "    \n",
    "    metric = None\n",
    "    for module_name in wer_modules:\n",
    "        try:\n",
    "            print(f\" 尝试加载: {module_name}\")\n",
    "            metric = evaluate.load(module_name, trust_remote_code=True)\n",
    "            print(f\" 成功加载: {module_name}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\" 失败: {e}\")\n",
    "    \n",
    "    if metric:\n",
    "        # 测试WER计算\n",
    "        test_preds = [\"hello world\"]\n",
    "        test_refs = [\"hello world\"]\n",
    "        wer_score = metric.compute(predictions=test_preds, references=test_refs)\n",
    "        print(f\" WER测试成功: {wer_score}\")\n",
    "    else:\n",
    "        print(\" 所有WER模块都加载失败\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\" 在临时目录中也失败: {e}\")\n",
    "\n",
    "finally:\n",
    "    # 6. 恢复原目录\n",
    "    os.chdir(original_dir)\n",
    "    print(f\" 恢复到原目录: {original_dir}\")\n",
    "\n",
    "print(\" 路径修复测试完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "698b74a4-71a7-4b25-9902-e1c28637d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 放弃 evaluate.wer评估方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c09485-08be-4d0b-9b9c-b8ab57aeef7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 测试jiwer...\n",
      " WER计算成功: 0.0\n",
      " WER百分比: 0.00%\n",
      "\n",
      " 测试包装器...\n",
      " 批次测试: 0.0\n",
      " 直接测试: 0.0\n",
      "\n",
      " jiwer解决方案准备完成！\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n 测试jiwer...\")\n",
    "\n",
    "# 测试数据\n",
    "references = [\"这是一个测试句子\", \"你好世界\"]\n",
    "predictions = [\"这是一个测试句子\", \"你好世界\"]\n",
    "\n",
    "# 计算WER\n",
    "wer_score = jiwer.wer(references, predictions)\n",
    "print(f\" WER计算成功: {wer_score}\")\n",
    "print(f\" WER百分比: {wer_score * 100:.2f}%\")\n",
    "\n",
    "# 3. 创建兼容evaluate接口的包装器\n",
    "class JiwerMetric:\n",
    "    \"\"\"jiwer包装器，兼容evaluate接口\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.predictions = []\n",
    "        self.references = []\n",
    "    \n",
    "    def add_batch(self, predictions, references):\n",
    "        \"\"\"添加批次数据\"\"\"\n",
    "        self.predictions.extend(predictions)\n",
    "        self.references.extend(references)\n",
    "    \n",
    "    def compute(self, predictions=None, references=None):\n",
    "        \"\"\"计算WER\"\"\"\n",
    "        if predictions is not None and references is not None:\n",
    "            return jiwer.wer(references, predictions)\n",
    "        else:\n",
    "            if not self.predictions or not self.references:\n",
    "                return 0.0\n",
    "            \n",
    "            wer_result = jiwer.wer(self.references, self.predictions)\n",
    "            \n",
    "            # 清空数据\n",
    "            self.predictions = []\n",
    "            self.references = []\n",
    "            \n",
    "            return wer_result\n",
    "\n",
    "# 4. 测试包装器\n",
    "print(\"\\n 测试包装器...\")\n",
    "metric = JiwerMetric()\n",
    "\n",
    "# 测试批次添加\n",
    "metric.add_batch(predictions=[\"测试1\"], references=[\"测试1\"])\n",
    "metric.add_batch(predictions=[\"测试2\"], references=[\"测试2\"])\n",
    "wer_batch = metric.compute()\n",
    "print(f\" 批次测试: {wer_batch}\")\n",
    "\n",
    "# 测试直接计算\n",
    "wer_direct = metric.compute(predictions=[\"直接测试\"], references=[\"直接测试\"])\n",
    "print(f\" 直接测试: {wer_direct}\")\n",
    "\n",
    "print(\"\\n jiwer解决方案准备完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c7bb34-82ce-4f63-b273-d815ec10dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 完整测试集评估准备\n",
      "测试集大小: 10581\n",
      " 批次大小: 16\n",
      "总批次数: 662\n",
      "开始完整测试集评估...\n",
      "这可能需要较长时间，请耐心等待...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:   0%|                                                                                                                                                     | 0/662 [00:00<?, ?it/s]/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/librosa/core/intervals.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n",
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "完整评估进度:   0%|▏                                                                                                                                          | 1/662 [00:17<3:18:00, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 16/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:   3%|████▍                                                                                                                                     | 21/662 [06:04<3:16:04, 18.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 336/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:   6%|████████▌                                                                                                                                 | 41/662 [11:02<2:25:51, 14.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 656/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:   9%|████████████▋                                                                                                                             | 61/662 [16:11<2:42:36, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 976/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  12%|████████████████▉                                                                                                                         | 81/662 [21:15<2:22:16, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 1296/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  15%|████████████████████▉                                                                                                                    | 101/662 [26:43<2:40:25, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 1616/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  18%|█████████████████████████                                                                                                                | 121/662 [31:51<2:26:57, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 1936/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  21%|█████████████████████████████▏                                                                                                           | 141/662 [37:22<2:23:24, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 2256/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  24%|█████████████████████████████████▎                                                                                                       | 161/662 [42:40<2:16:41, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 2576/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  27%|█████████████████████████████████████▍                                                                                                   | 181/662 [47:58<1:58:46, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 2896/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  30%|█████████████████████████████████████████▌                                                                                               | 201/662 [53:28<2:07:33, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 3216/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  33%|█████████████████████████████████████████████▋                                                                                           | 221/662 [58:26<1:56:22, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 3536/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  36%|█████████████████████████████████████████████████▏                                                                                     | 241/662 [1:03:36<1:51:18, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 3856/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  39%|█████████████████████████████████████████████████████▏                                                                                 | 261/662 [1:08:47<1:41:55, 15.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 4176/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  42%|█████████████████████████████████████████████████████████▎                                                                             | 281/662 [1:14:04<1:35:38, 15.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 4496/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  45%|█████████████████████████████████████████████████████████████▍                                                                         | 301/662 [1:19:27<1:32:29, 15.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 4816/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  48%|█████████████████████████████████████████████████████████████████▍                                                                     | 321/662 [1:25:13<1:32:10, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 5136/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  52%|█████████████████████████████████████████████████████████████████████▌                                                                 | 341/662 [1:30:40<1:29:02, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 5456/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  55%|█████████████████████████████████████████████████████████████████████████▌                                                             | 361/662 [1:35:59<1:23:17, 16.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 5776/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  58%|█████████████████████████████████████████████████████████████████████████████▋                                                         | 381/662 [1:41:08<1:12:52, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 6096/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  61%|█████████████████████████████████████████████████████████████████████████████████▊                                                     | 401/662 [1:46:29<1:05:49, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 6416/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  64%|█████████████████████████████████████████████████████████████████████████████████████▊                                                 | 421/662 [1:51:35<1:06:02, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 6736/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  67%|█████████████████████████████████████████████████████████████████████████████████████████▉                                             | 441/662 [1:56:58<1:03:59, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 7056/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  70%|███████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 461/662 [2:02:41<57:36, 17.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 7376/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  73%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                     | 481/662 [2:07:53<47:45, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 7696/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  76%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 501/662 [2:13:05<44:05, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 8016/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  79%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                             | 521/662 [2:18:28<39:16, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 8336/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 541/662 [2:23:40<30:27, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 8656/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                     | 561/662 [2:28:55<26:13, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 8976/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 581/662 [2:34:33<23:57, 17.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 9296/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 601/662 [2:39:49<14:59, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 9616/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 621/662 [2:45:06<10:37, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 9936/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度:  97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 641/662 [2:50:23<05:46, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 10256/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 661/662 [2:55:41<00:16, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理: 10576/10581 样本\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "完整评估进度: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 662/662 [2:55:51<00:00, 15.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完整测试集评估数据收集完成\n",
      "计算完整测试集WER...\n",
      "\n",
      "======================================================================\n",
      "Whisper LoRA 中文ASR模型 - 完整测试集评估结果\n",
      "======================================================================\n",
      "测试样本总数: 10581\n",
      "词错误率 (WER): 68.67%\n",
      "词准确率: 31.33%\n",
      "======================================================================\n",
      "完整测试集评估完成！\n",
      "最终结果: {'wer': 0.6867321867321867, 'wer_percent': 68.67321867321867, 'accuracy': 31.32678132678133, 'total_samples': 10581, 'dataset': 'full_test_set'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 完测试集评估\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "import jiwer\n",
    "\n",
    "# 创建评估数据加载器 - 使用完整测试集\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_common_voice[\"test\"], \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "print(f\" 完整测试集评估准备\")\n",
    "print(f\"测试集大小: {len(tokenized_common_voice['test'])}\")\n",
    "print(f\" 批次大小: {batch_size}\")\n",
    "print(f\"总批次数: {len(eval_dataloader)}\")\n",
    "\n",
    "# 创建评估器\n",
    "class FullDatasetWEREvaluator:\n",
    "    def __init__(self):\n",
    "        self.predictions = []\n",
    "        self.references = []\n",
    "    \n",
    "    def add_batch(self, predictions, references):\n",
    "        self.predictions.extend(predictions)\n",
    "        self.references.extend(references)\n",
    "    \n",
    "    def compute(self):\n",
    "        if not self.predictions:\n",
    "            return 0.0\n",
    "        return jiwer.wer(self.references, self.predictions)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            'total_samples': len(self.predictions),\n",
    "            'total_references': len(self.references)\n",
    "        }\n",
    "\n",
    "# 初始化评估器\n",
    "metric = FullDatasetWEREvaluator()\n",
    "\n",
    "print(\"开始完整测试集评估...\")\n",
    "print(\"这可能需要较长时间，请耐心等待...\")\n",
    "\n",
    "# 评估循环\n",
    "processed_samples = 0\n",
    "for step, batch in enumerate(tqdm(eval_dataloader, desc=\"完整评估进度\")):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            # 生成预测\n",
    "            generated_tokens = peft_model.generate(\n",
    "                input_features=batch[\"input_features\"].to(\"cuda\"),\n",
    "                max_new_tokens=255,\n",
    "            ).cpu().numpy()\n",
    "            \n",
    "            # 处理标签\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "            \n",
    "            # 解码\n",
    "            decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            \n",
    "            # 添加到评估器\n",
    "            metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "            processed_samples += len(decoded_preds)\n",
    "    \n",
    "    # 内存清理\n",
    "    del generated_tokens, labels, batch\n",
    "    if step % 20 == 0:  # 更频繁的内存清理\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"已处理: {processed_samples}/{len(tokenized_common_voice['test'])} 样本\")\n",
    "\n",
    "print(\"完整测试集评估数据收集完成\")\n",
    "\n",
    "# 计算最终WER\n",
    "print(\"计算完整测试集WER...\")\n",
    "wer_score = metric.compute()\n",
    "wer_percent = wer_score * 100\n",
    "stats = metric.get_stats()\n",
    "\n",
    "# 显示结果\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Whisper LoRA 中文ASR模型 - 完整测试集评估结果\")\n",
    "print(\"=\"*70)\n",
    "print(f\"测试样本总数: {stats['total_samples']}\")\n",
    "print(f\"词错误率 (WER): {wer_percent:.2f}%\")\n",
    "print(f\"词准确率: {100-wer_percent:.2f}%\")\n",
    "print(\"=\"*70)\n",
    "print(\"完整测试集评估完成！\")\n",
    "\n",
    "# 保存结果\n",
    "results = {\n",
    "    'wer': wer_score,\n",
    "    'wer_percent': wer_percent,\n",
    "    'accuracy': 100 - wer_percent,\n",
    "    'total_samples': stats['total_samples'],\n",
    "    'dataset': 'full_test_set'\n",
    "}\n",
    "\n",
    "print(f\"最终结果: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9d2895-4752-40ef-88cc-f5021b9aeb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
