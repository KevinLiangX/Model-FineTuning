{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d2d556-3c21-4027-b44d-73ad327b0488",
   "metadata": {},
   "source": [
    "# ÊµãËØïÁéØÂ¢É‰ª£ÁêÜÊòØÂê¶Ê≠£Â∏∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc351a7-686d-43ee-ac26-3c20c3a30e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ HuggingFace ËøûÊé•ÊàêÂäüÔºåÁä∂ÊÄÅÁ†Å: 200\n"
     ]
    }
   ],
   "source": [
    "# ÊµãËØï‰ª£ÁêÜ\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# ËÆæÁΩÆ‰ª£ÁêÜÁéØÂ¢ÉÂèòÈáè\n",
    "os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "os.environ['ALL_PROXY'] = 'socks5://127.0.0.1:7891'\n",
    "\n",
    "# ÊµãËØï‰ª£ÁêÜËøûÊé•\n",
    "try:\n",
    "    response = requests.get('https://huggingface.co', timeout=10)\n",
    "    print(\"‚úÖ HuggingFace ËøûÊé•ÊàêÂäüÔºåÁä∂ÊÄÅÁ†Å:\", response.status_code)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ËøûÊé•Â§±Ë¥•:\", e)\n",
    "\n",
    "# ËÆæÁΩÆ HuggingFace ÁºìÂ≠òË∑ØÂæÑ\n",
    "os.environ['HF_HOME'] = '/home/KevinLiangX/Codes/LLM-quickstart-main/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/home/KevinLiangX/Codes/LLM-quickstart-main/hf_hu'\n",
    "\n",
    "# ÊúçÂä°Âô®ÁéØÂ¢É ubuntu22.04 GPU 2080Ti 22G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e5b7c-ef88-42f0-84a8-d8f0de52ac78",
   "metadata": {},
   "source": [
    "# ‰∏ãËΩΩÊµãËØïÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fe00ff-a73c-43c1-92de-ed207457c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a5906-6c61-4fb1-bd18-06365cf1a868",
   "metadata": {},
   "source": [
    "# È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d07c6bf-1a91-4a48-b08b-1f8685ad26b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/KevinLiangX/Codes/LLM-quickstart-main/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Â°´ÂÖÖÂà∞ÊúÄÂ§ßÈïøÂ∫¶ÁöÑÁ≠ñÁï•ÔºåÂ§ÑÁêÜÊï¥‰∏™Êï∞ÊçÆÈõÜÔºö\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef31b8c-6071-4958-887a-603005ef6adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Êï∞ÊçÆÈõÜ‰ø°ÊÅØ:\n",
      "   ËÆ≠ÁªÉÈõÜ: 650,000 Ê†∑Êú¨\n",
      "   ËØÑ‰º∞ÈõÜ: 50,000 Ê†∑Êú¨\n"
     ]
    }
   ],
   "source": [
    "# ÂÆåÊï¥ËÆ≠ÁªÉÈõÜ\n",
    "full_train_dataset = tokenized_datasets[\"train\"]\n",
    "full_eval_dataset = tokenized_datasets[\"test\"]\n",
    "print(f\"üìä Êï∞ÊçÆÈõÜ‰ø°ÊÅØ:\")\n",
    "print(f\"   ËÆ≠ÁªÉÈõÜ: {len(full_train_dataset):,} Ê†∑Êú¨\")\n",
    "print(f\"   ËØÑ‰º∞ÈõÜ: {len(full_eval_dataset):,} Ê†∑Êú¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32f2dc-eb74-4c6b-919b-fe404be7ddb1",
   "metadata": {},
   "source": [
    "# ÂæÆË∞ÉÈÖçÁΩÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b2c6d1-bc03-45b0-9170-7d18187853b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddd3606-51d0-4e4b-ae7c-71ebecb2ced1",
   "metadata": {},
   "source": [
    "## ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÁöÑËØÑ‰º∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e87455-51ac-4281-8181-ed3b5be47d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ËØÑ‰º∞ÂáΩÊï∞Â∑≤ÂÆö‰πâ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"ËÆ°ÁÆóÂáÜÁ°ÆÁéáÊåáÊ†á\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "print(\"‚úÖ ËØÑ‰º∞ÂáΩÊï∞Â∑≤ÂÆö‰πâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ec83a-bdd3-49b1-aa1e-ae7609fde47e",
   "metadata": {},
   "source": [
    "## ËÆ≠ÁªÉË∂ÖÂèÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66da2213-8781-4e93-be3b-ec3fc77b0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = \"models/bert-base-cased-finetune-yelp\"\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    \n",
    "    # === ËØÑ‰º∞Á≠ñÁï• === Yelp ‰ΩøÁî®stepËØÑ‰º∞ÊØîepochÂ•Ω\n",
    "    evaluation_strategy=\"steps\", # ÊåâËÆ≠ÁªÉÊ≠•Êï∞ËøõË°åËØÑ‰º∞Ôºå YelpÊï∞ÊçÆÈõÜÂ§ß(650KÊ†∑Êú¨)ÔºåÊØèepochÁ∫¶20KÊ≠•ÔºåYelpÊï∞ÊçÆÈõÜÂ§ß(650KÊ†∑Êú¨)ÔºåÊØèepochÁ∫¶20KÊ≠•\n",
    "    save_strategy=\"steps\", # ÊåâËÆ≠ÁªÉÊ≠•Êï∞‰øùÂ≠òÊ®°ÂûãcheckpointÔºå ‰∏éËØÑ‰º∞Á≠ñÁï•‰øùÊåÅ‰∏ÄËá¥Ôºå ÂèäÊó∂‰øùÂ≠òÊúÄ‰Ω≥Ê®°ÂûãÔºåÈÅøÂÖç‰∏¢Â§±\n",
    "    logging_strategy=\"steps\", #ÊåâËÆ≠ÁªÉÊ≠•Êï∞ËÆ∞ÂΩïÊó•ÂøóÔºåÊèê‰æõËØ¶ÁªÜÁöÑËÆ≠ÁªÉËøáÁ®ãÁõëÊéßÔºå‰æø‰∫éË∞ÉËØïÂíåÂàÜÊûêËÆ≠ÁªÉÊõ≤Á∫ø\n",
    "    eval_steps=500,  # ÊØè500Ê≠•ËØÑ‰º∞‰∏ÄÊ¨°ÔºåÁ∫¶ÊØèochËØÑ‰º∞20Ê¨° ep(20K/500)ÔºåÂπ≥Ë°°ËØÑ‰º∞È¢ëÁéáÂíåËÆ≠ÁªÉÊïàÁéáÔºåÂπ≥Ë°°ËØÑ‰º∞È¢ëÁéáÂíåËÆ≠ÁªÉÊïàÁéá\n",
    "    save_steps=500, # ÊØè500Ê≠•‰øùÂ≠ò‰∏ÄÊ¨°checkpointÔºå‰∏éeval_stepsÂêåÊ≠•Ôºå‰øùÂ≠òÊúÄ‰Ω≥Ê®°# ÊØè500Ê≠•ËÆ∞ÂΩï‰∏ÄÊ¨°ËÆ≠ÁªÉÊó•Âøó\n",
    "    logging_steps=50, # ÊØè50Ê≠•ËÆ∞ÂΩï‰∏ÄÊ¨°ËÆ≠ÁªÉÊó•ÂøóÔºåÊèê‰æõËØ¶ÁªÜÁöÑlossÂèòÂåñÊõ≤Á∫ø #\n",
    "    \n",
    "    # === ËÆ≠ÁªÉÈÖçÁΩÆ ===\n",
    "    per_device_train_batch_size=32, # ÊØè‰∏™GPUÁöÑËÆ≠ÁªÉÊâπÊ¨°Â§ßÂ∞èÔºåÂπ≥Ë°°ÊòæÂ≠ò‰ΩøÁî®ÂíåËÆ≠ÁªÉÁ®≥ÂÆöÊÄßÔºå32Ê†∑Êú¨ √ó 512ÈïøÂ∫¶ √ó 4Â≠óËäÇÔºåËæÉÂ∞èbatch_sizeËÆ≠ÁªÉÊõ¥Á®≥ÂÆö\n",
    "    per_device_eval_batch_size=64, # ÊØè‰∏™GPUÁöÑËØÑ‰º∞ÊâπÊ¨°Â§ßÂ∞èÔºåËØÑ‰º∞Êó∂‰∏çÈúÄË¶ÅÊ¢ØÂ∫¶ÔºåÂèØ‰ª•Áî®Êõ¥Â§ßbatchÔºåÂä†ÈÄüËØÑ‰º∞ËøáÁ®ãÔºåËäÇÁúÅÊó∂Èó¥\n",
    "    gradient_accumulation_steps=2, # Á¥ØÁßØX‰∏™batchÁöÑÊ¢ØÂ∫¶ÂÜçÊõ¥Êñ∞ÔºåÂú®ÊòæÂ≠òÈôêÂà∂‰∏ãÊ®°ÊãüÂ§ßbatch_sizeÔºåËé∑ÂæóÂ§ßbatch_sizeÁöÑËÆ≠ÁªÉÊïàÊûú\n",
    "    num_train_epochs=2, # ËÆ≠ÁªÉ2‰∏™ÂÆåÊï¥ÁöÑÊï∞ÊçÆÈÅçÂéÜÔºåBERTÂú®Â§ßÊï∞ÊçÆÈõÜ‰∏äÈÄöÂ∏∏2-4‰∏™epochÊúÄ‰ºòÔºå1 epochÊ¨†ÊãüÂêàÔºå5+ epochËøáÊãüÂêàÔºåYelpÁâπÁÇπ: 3‰∏™epochÈÄöÂ∏∏ËÉΩËææÂà∞ÊúÄ‰Ω≥ÊÄßËÉΩ\n",
    "    \n",
    "    # === Â≠¶‰π†Áéá‰ºòÂåñ===\n",
    "    learning_rate=2.5e-5, # BERTÂæÆË∞ÉÁöÑÁªèÂÖ∏Â≠¶‰π†ÁéáËåÉÂõ¥[1e-5, 5e-5]Ôºå2e-5ÊòØÂπ≥Ë°°Êî∂ÊïõÈÄüÂ∫¶ÂíåÁ®≥ÂÆöÊÄßÁöÑÁîúÁÇπÔºåÂ§™Â§ß(>5e-5)‰∏çÁ®≥ÂÆöÔºåÂ§™Â∞è(<1e-5)Êî∂ÊïõÊÖ¢\n",
    "    weight_decay=0.01, # L2Ê≠£ÂàôÂåñÁ≥ªÊï∞ÔºåÈò≤Ê≠¢ÊùÉÈáçËøáÂ§ßÔºåÈò≤Ê≠¢ËøáÊãüÂêàÔºåÊèêÈ´òÊ≥õÂåñËÉΩÂäõÔºåloss = original_loss + 0.01 √ó ||weights||¬≤Ôºå0.01ÊòØBERTÂæÆË∞ÉÁöÑÊ†áÂáÜËÆæÁΩÆ\n",
    "    warmup_steps=800, # ÂâçxxxÊ≠•ÁöÑÁ∫øÊÄßÂ¢ûÂä†Â≠¶‰π†ÁéáÔºåÈÅøÂÖçËÆ≠ÁªÉÂàùÊúüÂ≠¶‰π†ÁéáËøáÂ§ßÂØºËá¥‰∏çÁ®≥ÂÆöÔºåÁ∫¶Âç†ÊÄªÊ≠•Êï∞ÁöÑ3-5% (2000/60000)Ôºå0 ‚Üí 3.2e-5 (Á∫øÊÄßÂ¢ûÈïø) ÊÄªÊ≠•Êï∞3%\n",
    "    lr_scheduler_type=\"cosine\", # ‰ΩôÂº¶ÈÄÄÁÅ´Â≠¶‰π†ÁéáË∞ÉÂ∫¶ÔºåËÆ≠ÁªÉÂêéÊúüÁºìÊÖ¢Èôç‰ΩéÂ≠¶‰π†ÁéáÔºåÁ≤æÁªÜË∞É‰ºòÔºålr = lr_min + (lr_max - lr_min) √ó (1 + cos(œÄ√ót/T))/2ÔºåÊØîÁ∫øÊÄßË°∞ÂáèÊõ¥Âπ≥ÊªëÔºåÈÅøÂÖçÈúáËç°\n",
    "    \n",
    "    # === Ê≠£ÂàôÂåñ ===\n",
    "    label_smoothing_factor=0.1,# Ê†áÁ≠æÂπ≥ÊªëÔºåËΩØÂåñone-hotÊ†áÁ≠æÔºåÈÄöÂ∏∏ËÉΩÊèêÂçá0.5-1%ÁöÑÂáÜÁ°ÆÁéá\n",
    "    \n",
    "    # === ÊÄßËÉΩ‰ºòÂåñ ===\n",
    "    fp16=True, # ‰ΩøÁî®16‰ΩçÊµÆÁÇπÊï∞‰ª£Êõø32‰ΩçÔºåË∑ü2080TiÊòæÂç°ÊúâÂÖ≥\n",
    "    dataloader_num_workers=2, # ÈÄÇ‰∏≠Â§öËøõÁ®ãÔºåÈÅøÂÖçËøáÂ§öËøõÁ®ãÁ´û‰∫â\n",
    "    gradient_checkpointing=False, # ÈáçÊñ∞ËÆ°ÁÆó‰∏≠Èó¥ÊøÄÊ¥ªÂÄºËÄå‰∏çÊòØÂ≠òÂÇ®ÔºåÊòæÂ≠ò‰∏çË∂≥Êó∂ÁöÑÂøÖË¶ÅÈÄâÊã©\n",
    "    dataloader_pin_memory=True,\n",
    "    max_grad_norm=1.0,         # Ê¢ØÂ∫¶Ë£ÅÂâ™ÔºåÈò≤Ê≠¢Ê¢ØÂ∫¶ÁàÜÁÇ∏\n",
    "    \n",
    "    # === Ê®°ÂûãÈÄâÊã© ===\n",
    "    load_best_model_at_end=True, # ËÆ≠ÁªÉÁªìÊùüÂêéÂä†ËΩΩÊúÄ‰Ω≥checkpoint\n",
    "    metric_for_best_model=\"eval_accuracy\", # ‰ΩøÁî®È™åËØÅÂáÜÁ°ÆÁéá‰Ωú‰∏∫ÊúÄ‰Ω≥Ê®°ÂûãÊ†áÂáÜ\n",
    "    greater_is_better=True, # ÂáÜÁ°ÆÁéáË∂äÈ´òË∂äÂ•Ω\n",
    "    save_total_limit=2, # ÊúÄÂ§ö‰øùÁïô2‰∏™checkpoint\n",
    "\n",
    "    # === ÁõëÊéß===\n",
    "    logging_dir=f'{model_dir}/logs',\n",
    "\n",
    "    # === ÂÖ∂‰ªñ‰ºòÂåñ ===\n",
    "    remove_unused_columns=True,\n",
    "    seed=42, # ÈöèÊú∫ÁßçÂ≠êÔºåÁ°Æ‰øùÁªìÊûúÂèØÂ§çÁé∞\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83a498-934d-4494-b84c-ab0c956843ce",
   "metadata": {},
   "source": [
    "#  ÂºÄÂßãËÆ≠ÁªÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f94708-ab0b-4c2b-90f4-485d2b260feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TrainerÂ∑≤ÂàõÂª∫ÔºåÂáÜÂ§áÂºÄÂßãËÆ≠ÁªÉ...\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=full_train_dataset,\n",
    "    eval_dataset=full_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"üöÄ TrainerÂ∑≤ÂàõÂª∫ÔºåÂáÜÂ§áÂºÄÂßãËÆ≠ÁªÉ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49de6802-273f-4094-828c-3681b713dd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20312' max='20312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20312/20312 8:38:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.098800</td>\n",
       "      <td>1.090557</td>\n",
       "      <td>0.581040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.044000</td>\n",
       "      <td>1.073347</td>\n",
       "      <td>0.605460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.011900</td>\n",
       "      <td>1.004492</td>\n",
       "      <td>0.641460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.003700</td>\n",
       "      <td>0.972724</td>\n",
       "      <td>0.658960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.978500</td>\n",
       "      <td>0.966885</td>\n",
       "      <td>0.662680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>0.964803</td>\n",
       "      <td>0.665780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.944400</td>\n",
       "      <td>0.961881</td>\n",
       "      <td>0.668760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.947300</td>\n",
       "      <td>0.964928</td>\n",
       "      <td>0.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.966000</td>\n",
       "      <td>0.946655</td>\n",
       "      <td>0.676380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.943000</td>\n",
       "      <td>0.959583</td>\n",
       "      <td>0.670920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.945800</td>\n",
       "      <td>0.939840</td>\n",
       "      <td>0.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.926600</td>\n",
       "      <td>0.944650</td>\n",
       "      <td>0.676520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.932400</td>\n",
       "      <td>0.933138</td>\n",
       "      <td>0.683280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.945300</td>\n",
       "      <td>0.933277</td>\n",
       "      <td>0.682660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.931700</td>\n",
       "      <td>0.927414</td>\n",
       "      <td>0.687600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.925200</td>\n",
       "      <td>0.930594</td>\n",
       "      <td>0.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.922900</td>\n",
       "      <td>0.930946</td>\n",
       "      <td>0.684200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.918900</td>\n",
       "      <td>0.920988</td>\n",
       "      <td>0.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.939700</td>\n",
       "      <td>0.919582</td>\n",
       "      <td>0.691340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.929600</td>\n",
       "      <td>0.919771</td>\n",
       "      <td>0.690880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.891400</td>\n",
       "      <td>0.915949</td>\n",
       "      <td>0.694120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.918637</td>\n",
       "      <td>0.693360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.876900</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>0.692260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.863300</td>\n",
       "      <td>0.927443</td>\n",
       "      <td>0.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.885300</td>\n",
       "      <td>0.915403</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.902000</td>\n",
       "      <td>0.915161</td>\n",
       "      <td>0.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.694700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.915487</td>\n",
       "      <td>0.695860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.879400</td>\n",
       "      <td>0.914805</td>\n",
       "      <td>0.695820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.850100</td>\n",
       "      <td>0.919024</td>\n",
       "      <td>0.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.873600</td>\n",
       "      <td>0.914920</td>\n",
       "      <td>0.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.861900</td>\n",
       "      <td>0.915016</td>\n",
       "      <td>0.697480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.875700</td>\n",
       "      <td>0.913501</td>\n",
       "      <td>0.696460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>0.913410</td>\n",
       "      <td>0.698520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.866600</td>\n",
       "      <td>0.910923</td>\n",
       "      <td>0.698480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.865500</td>\n",
       "      <td>0.911370</td>\n",
       "      <td>0.698280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.867800</td>\n",
       "      <td>0.911262</td>\n",
       "      <td>0.698400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.873700</td>\n",
       "      <td>0.911552</td>\n",
       "      <td>0.698620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>0.910852</td>\n",
       "      <td>0.698680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.910782</td>\n",
       "      <td>0.698740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20312, training_loss=0.9252217751687415, metrics={'train_runtime': 31118.6981, 'train_samples_per_second': 41.776, 'train_steps_per_second': 0.653, 'total_flos': 3.420409555323617e+17, 'train_loss': 0.9252217751687415, 'epoch': 2.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7ab84d-344d-4350-8e73-e0bd1f0a88e5",
   "metadata": {},
   "source": [
    "# ÊÑüËßâÁ≤æÁ°ÆÂ∫¶‰πü‰∏çÈ´òÂìàÔºåËÆ≠ÁªÉ‰∫ÜÂø´8‰∏™Â∞èÊó∂ÔºåË∞É‰∫Ü‰∏ãÁ¨¶ÂêàÁõÆÂâçÊàëËá™Â∑±ÊòæÂç°ËÉΩÊâøÂèóÁöÑËåÉÂõ¥ÁöÑË∂ÖÂèÇÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ac3a5-b4f3-4166-9e7b-00d254f6f676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
